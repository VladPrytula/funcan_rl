# Project 8.5: Connect Four with Monte Carlo Tree Search

**Status**: Complete (Environment + MCTS + Terminal + Web Interface)
**Implementation Date**: October 2025 (Week 2, 29 weeks ahead of Syllabus Week 31)
**Documentation**: [Quick Start](QUICKSTART.md) â€¢ [Tutorial](TUTORIAL.md) â€¢ [Advanced Topics](ADVANCED.md)

---

## Overview

This project implements Connect Four AI using **Monte Carlo Tree Search (MCTS) with UCT** (Upper Confidence bounds for Trees), demonstrating the connection between bandit theory (Weeks 27-28) and game tree search.

**Key Innovation**: Real-time visualization of MCTS search statistics exposes the exploration-exploitation tradeoff in action.

---

## ğŸš€ Quick Start

```bash
# Terminal play with AI thinking visualization
cd /path/to/Study
PYTHONPATH="code:$PYTHONPATH" python code/projects/project_08.5_connect_four/play_terminal.py --show-search-tree

# Web interface
python code/projects/project_08.5_connect_four/web_app.py
# Open http://localhost:5002/connect-four
```

**See [QUICKSTART.md](QUICKSTART.md) for detailed usage and options.**

---

## ğŸ¯ Theory Connections

### 1. Connect Four as Finite MDP ([THM-24.X.Y])

**MDP Formulation:**
- **State space S**: Game positions (4.5 trillion reachable states)
- **Action space A(s)**: Columns with empty top cell (max 7)
- **Transition P**: Deterministic (piece drops via gravity)
- **Reward R**: +1 (win), -1 (loss), 0 (draw)
- **Discount Î³**: 1 (episodic, no discounting)

**Bellman Optimality**: V*(s) = max_a [R(s,a) + Î³ Î£ P(s'|s,a) V*(s')]

**Complexity**: 4.5 trillion states â†’ exact search intractable â†’ MCTS approximates V* via sampling

**References**:
- Allis (1988): Connect Four is solved (first player wins with perfect play)
- Our approach: MCTS approximates V* via Monte Carlo sampling

---

### 2. MCTS as UCB1 on Game Trees ([THM-28.X.Y])

**Key Insight**: Each MCTS node is a multi-armed bandit problem.

**UCT Formula (Upper Confidence bounds for Trees)**:
```
UCT(s,a) = Q(s,a) + câˆš(ln N(s) / N(s,a))
           â†‘           â†‘
     Exploitation  Exploration
```

Where:
- `Q(s,a) = W(s,a) / N(s,a)`: Average value from action a
- `c = âˆš2 â‰ˆ 1.41`: Exploration constant (theoretically optimal)
- `N(s)`: Parent visit count
- `N(s,a)`: Child visit count

**Theory ([THM-28.X.Y])**:
- **UCB1 regret bound**: O(âˆš(K log n / n)) per node (K arms, n trials)
- **MCTS convergence**: UCT converges to minimax in the limit
- **Asymmetric growth**: Tree expands toward promising moves

**Practice**:
- **Move selection**: argmax N(s,a) (most visited), not argmax Q(s,a)
- **Why**: Visit count more robust to outlier simulations

---

### 3. Heuristic Evaluation as Approximate Value Function

**Theory ([THM-24.X.Y])**: V*(s) = exact Bellman backup (requires full game tree)

**Practice**: h(s) â‰ˆ V*(s) via domain knowledge (pattern recognition)

**Our Heuristic Algorithm**:
1. Open 3-in-a-row: +100 (immediate threat)
2. Open 2-in-a-row: +10 (potential)
3. Opponent threats: -100 (defensive)
4. Center column control: +3 per piece (positional bonus)
5. Normalize to [-1, 1]

**Theory-Practice Gap (Honest Assessment)**:
- âœ… **Theory guarantees**: V* is unique optimal value function
- âš ï¸ **Practice reality**: h(s) is "good enough," not optimal
- âœ… **Why it works**: Guides MCTS toward promising regions
- âŒ **When it fails**: Tactical positions (h misses forced wins/losses)

---

## ğŸ“‚ Implementation Structure

```
code/
â”œâ”€â”€ rl_toolkit/
â”‚   â”œâ”€â”€ envs/
â”‚   â”‚   â””â”€â”€ connect_four.py              # Game engine (300 lines)
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â””â”€â”€ mcts.py                      # MCTS with UCT (400 lines)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ board_viz.py                 # Extended for rectangular boards
â”‚
â”œâ”€â”€ projects/project_08.5_connect_four/
â”‚   â”œâ”€â”€ play_terminal.py                 # Terminal interface with --show-search-tree
â”‚   â”œâ”€â”€ web_app.py                       # Flask web server
â”‚   â”œâ”€â”€ test_mcts.py                     # MCTS algorithm tests (20 tests)
â”‚   â”œâ”€â”€ test_api.py                      # Web API tests (16 tests)
â”‚   â”œâ”€â”€ README.md                        # This file
â”‚   â”œâ”€â”€ QUICKSTART.md                    # 5-minute getting started
â”‚   â”œâ”€â”€ TUTORIAL.md                      # 4-session tutorial (330 min)
â”‚   â””â”€â”€ ADVANCED.md                      # MCTS upgrade notes (UCT â†’ AlphaZero)
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_connect_four.py             # Environment tests (29 tests)
```

**Reusable Infrastructure**:
- `MCTSSolver` works for any two-player zero-sum game (Gomoku, Reversi later)
- `get_position_name_rect()` handles rectangular boards
- Visualization patterns template for future projects

---

## ğŸ”§ Configuration Options

### MCTS Parameters

**`--num-simulations` (default: 1000)**
- More simulations â†’ stronger play, slower
- 100: Weak (for testing)
- 1000: Strong (default)
- 1600: Very strong (competitive)

**`--exploration-constant` (default: 1.41 = âˆš2)**
- Higher c â†’ more exploration
- Lower c â†’ more exploitation
- Theory: c = âˆš2 optimal for bounded rewards

**`--max-depth` (default: None)**
- Limit simulation depth, use heuristic at cutoff
- None: Simulate to game end (exact)
- 10-20: Faster, uses heuristic

**Board Size**: Default 6Ã—7 (standard Connect Four), configurable via `--board-size rowsÃ—cols`

---

## ğŸ§ª Testing & Validation

### Test Coverage

**Environment Tests** (`test_connect_four.py` - 29 tests):
- Gravity mechanics (5 tests)
- Win detection (5 tests: horizontal, vertical, diagonal)
- Game flow (4 tests: alternating turns, draw, reset, copy)
- Heuristic evaluation (5 tests: symmetry, terminal correctness, boundedness)
- Edge cases (5 tests: rectangular boards, full columns)

**MCTS Algorithm Tests** (`test_mcts.py` - 20 tests):
- UCT score computation (3 tests)
- Tree building (4 tests: selection, expansion, simulation, backpropagation)
- Convergence (3 tests: more simulations improve play, finds forced wins)
- Integration (4 tests: MCTS beats random 70%+, statistics tracking)
- Depth-limited search (3 tests: heuristic cutoff)
- Edge cases (3 tests: terminal states, single move)

**Web API Tests** (`test_api.py` - 16 tests):
- Game initialization, move validation, AI moves, statistics, error handling

**Total: 65 tests, all passing**

### Validation Results

**MCTS vs Random Play**: 70-90% win rate (10 games, 200 simulations per move)

**Search Statistics (1000 simulations)**:
- Nodes explored: 1000-1500 (tree grows asymmetrically)
- Max tree depth: 10-20 (depends on position)
- Time per move: ~0.5-1 second (Python, no optimization)

---

## ğŸ“Š MCTS Visualization

When you run with `--show-search-tree`, you see:

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MCTS Search Tree Statistics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Theory: UCT formula guides selection during tree search
  UCT(s,a) = Q(s,a) + câˆš(ln N(s) / N(s,a))
  Best move = argmax N(s,a) (most visited, not highest Q)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Column   Visits   Q-value    UCT        Assessment                          Best
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
a        347      +0.680        0.520   heavily explored, strong position    â­
b        128      +0.540        0.760   moderately explored, strong position
c        289      +0.620        0.580   heavily explored, strong position
d        94       +0.410        0.820   moderately explored, balanced
e        71       +0.280        0.910   lightly explored, balanced
f        42       +0.310        0.890   lightly explored, weak position
g        29       +0.150        1.020   lightly explored, weak position
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**What you're seeing**:
- **Visits**: N(s,a) - how many times MCTS explored this column
- **Q-value**: Average game outcome from this move (exploitation)
- **UCT**: UCT(s,a) score during search (exploration + exploitation)
- **Assessment**: Natural language interpretation
- **Best**: Most visited move (argmax N(s,a)) marked with â­

**Theory in Action**:
- Column `a` is best (most visited), despite other columns having higher Q-values
- Why? More visits = more confidence in the estimate
- Lightly explored moves (f, g) have high UCT â†’ will be explored more if promising

---

## ğŸ“– References

### Theory (Syllabus)

**Week 24 (MDPs)**:
- [THM-24.X.Y]: Bellman optimality equation characterizes V*(s)
- Connect Four as finite MDP with deterministic transitions

**Week 27-28 (Bandits)**:
- [THM-28.X.Y]: UCB1 achieves logarithmic regret
- UCT formula: Q(s,a) + câˆš(ln N(s) / N(s,a))
- MCTS as UCB1 recursively applied to game trees

### Papers

**Game Complexity**:
- Allis (1988): "A Knowledge-Based Approach of Connect-Four" (solved game)
- Tromp (2008): Number of legal positions: 4,531,985,219,092

**MCTS Theory**:
- Coulom (2006): "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"
- Kocsis & SzepesvÃ¡ri (2006): "Bandit based Monte-Carlo Planning"
- Browne et al. (2012): "A Survey of Monte Carlo Tree Search Methods"

**Bandit Theory**:
- Auer et al. (2002): "Finite-time Analysis of the Multiarmed Bandit Problem"
- Lattimore & SzepesvÃ¡ri (2020): "Bandit Algorithms"

---

## ğŸ“ Pedagogical Notes

### For Students

**What you should understand after this project**:

1. **MDP Formalism**: How to model a game as (S, A, P, R, Î³)
2. **Bandit Theory Application**: How UCB1 balances exploration-exploitation
3. **Theory-Practice Gaps**: When theory guarantees apply vs. when practice diverges

### For Instructors

**Using this project in class**:
- **Week 24 (MDPs)**: Use Connect Four as concrete MDP example
- **Week 27-28 (Bandits)**: Show how UCT extends UCB1 to trees
- **Lab Session**: Students implement MCTS from scratch using [TUTORIAL.md](TUTORIAL.md)
- **Visualization**: Use `--show-search-tree` to demonstrate exploration-exploitation live

**Key Learning Outcomes**:
- âœ… Students see bandits + MDPs unified in MCTS
- âœ… Visualization makes abstract theory concrete
- âœ… Honest gaps teach real-world ML engineering

---

## ğŸš€ Next Steps

**After this project**:

1. **Week 31 Refactoring**: Extract shared web framework (after Connect Four web interface)
2. **Week 40-41 (Gomoku)**: Extend MCTS with neural network evaluation
3. **Weeks 42-48 (AlphaZero-Lite)**: Add self-play training loop

**For deep dive into MCTS**:
- See [ADVANCED.md](ADVANCED.md) for UCT derivation, parallelization, AlphaZero extensions

---

## âœ… Deliverables Summary

**Complete (8 hours)**:
- âœ… Connect Four environment with gravity mechanics
- âœ… MCTS algorithm with UCT (reusable for Gomoku, Reversi)
- âœ… Terminal interface with search tree visualization
- âœ… Web interface with real-time MCTS stats
- âœ… 65 tests (environment + MCTS + API)
- âœ… Complete documentation (quick start, tutorial, advanced topics)

---

**Theory connections documented. Ready for educational use and extension to larger games.**

â€” Dr. Vlad Prytula
October 14, 2025
